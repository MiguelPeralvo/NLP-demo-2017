{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching package metadata ...........\n",
      "Solving package specifications: ..........\n",
      "\n",
      "Package plan for installation in environment /opt/conda/envs/python2:\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    cymem-1.31.2               |           py27_0          55 KB\n",
      "    murmurhash-0.26.4          |           py27_0          29 KB\n",
      "    pathlib-1.0.1              |           py27_0          25 KB\n",
      "    plac-0.9.6                 |           py27_0          31 KB\n",
      "    regex-2017.4.5             |           py27_0         568 KB\n",
      "    termcolor-1.1.0            |           py27_0           7 KB\n",
      "    tqdm-4.15.0                |           py27_0          48 KB\n",
      "    ujson-1.35                 |           py27_0          57 KB\n",
      "    wrapt-1.10.11              |           py27_0          64 KB\n",
      "    cytoolz-0.8.2              |           py27_0         913 KB\n",
      "    preshed-1.0.0              |           py27_0         191 KB\n",
      "    ftfy-4.4.3                 |           py27_0          51 KB\n",
      "    thinc-6.5.2                |           py27_0         2.0 MB\n",
      "    spacy-1.8.2                |           py27_0         7.3 MB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        11.4 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "    cymem:      1.31.2-py27_0  \n",
      "    cytoolz:    0.8.2-py27_0   \n",
      "    ftfy:       4.4.3-py27_0   \n",
      "    murmurhash: 0.26.4-py27_0  \n",
      "    pathlib:    1.0.1-py27_0   \n",
      "    plac:       0.9.6-py27_0   \n",
      "    preshed:    1.0.0-py27_0   \n",
      "    regex:      2017.4.5-py27_0\n",
      "    spacy:      1.8.2-py27_0   \n",
      "    termcolor:  1.1.0-py27_0   \n",
      "    thinc:      6.5.2-py27_0   \n",
      "    tqdm:       4.15.0-py27_0  \n",
      "    ujson:      1.35-py27_0    \n",
      "    wrapt:      1.10.11-py27_0 \n",
      "\n",
      "Fetching packages ...\n",
      "cymem-1.31.2-p 100% |################################| Time: 0:00:00   1.11 MB/s\n",
      "murmurhash-0.2 100% |################################| Time: 0:00:00 370.87 kB/s\n",
      "pathlib-1.0.1- 100% |################################| Time: 0:00:00 353.22 kB/s\n",
      "plac-0.9.6-py2 100% |################################| Time: 0:00:00   1.09 MB/s\n",
      "regex-2017.4.5 100% |################################| Time: 0:00:00 941.75 kB/s\n",
      "termcolor-1.1. 100% |################################| Time: 0:00:00 139.55 kB/s\n",
      "tqdm-4.15.0-py 100% |################################| Time: 0:00:00 467.13 kB/s\n",
      "ujson-1.35-py2 100% |################################| Time: 0:00:00 613.59 kB/s\n",
      "wrapt-1.10.11- 100% |################################| Time: 0:00:00   1.07 MB/s\n",
      "cytoolz-0.8.2- 100% |################################| Time: 0:00:00   1.06 MB/s\n",
      "preshed-1.0.0- 100% |################################| Time: 0:00:00 838.71 kB/s\n",
      "ftfy-4.4.3-py2 100% |################################| Time: 0:00:00 567.70 kB/s\n",
      "thinc-6.5.2-py 100% |################################| Time: 0:00:02 982.72 kB/s\n",
      "spacy-1.8.2-py 100% |################################| Time: 0:00:07   1.03 MB/s\n",
      "Extracting packages ...\n",
      "[      COMPLETE      ]|###################################################| 100%\n",
      "Linking packages ...\n",
      "[      COMPLETE      ]|###################################################| 100%\n"
     ]
    }
   ],
   "source": [
    "!conda install -y spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[93m    Warning: no model found for 'en'\u001b[0m\n",
      "\n",
      "    Only loading the 'en' tokenizer.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import spacy                        \n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Sentence detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language: en\n",
      "Vocabulary size: 1297614\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Start</th>\n",
       "      <th>End</th>\n",
       "      <th>Sentence Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>Prescribing sick days due to diagnosis of infl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>17</td>\n",
       "      <td>Jane complains about flu-like symptoms.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17</td>\n",
       "      <td>27</td>\n",
       "      <td>Jane may be experiencing some sort of flu epis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27</td>\n",
       "      <td>37</td>\n",
       "      <td>Jane’s RIDT came back negative for influenza.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37</td>\n",
       "      <td>50</td>\n",
       "      <td>Jane is at high risk for flu if she’s not vacc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>50</td>\n",
       "      <td>60</td>\n",
       "      <td>Jane’s older brother had the flu last month.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>60</td>\n",
       "      <td>70</td>\n",
       "      <td>Jane had a severe case of flu last year.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>70</td>\n",
       "      <td>81</td>\n",
       "      <td>Joe expressed concerns about the risks of bird...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>81</td>\n",
       "      <td>92</td>\n",
       "      <td>Joe shows no signs of stroke, except for numbn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>92</td>\n",
       "      <td>100</td>\n",
       "      <td>Nausea, vomiting and ankle swelling negative.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>100</td>\n",
       "      <td>105</td>\n",
       "      <td>Patient denies alcohol abuse.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>105</td>\n",
       "      <td>114</td>\n",
       "      <td>Allergies: Penicillin, Dust, Sneezing.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>114</td>\n",
       "      <td>140</td>\n",
       "      <td>There's an outbreak of happiness in San Jose o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Start  End                                      Sentence Text\n",
       "0       0    9  Prescribing sick days due to diagnosis of infl...\n",
       "1       9   17            Jane complains about flu-like symptoms.\n",
       "2      17   27  Jane may be experiencing some sort of flu epis...\n",
       "3      27   37      Jane’s RIDT came back negative for influenza.\n",
       "4      37   50  Jane is at high risk for flu if she’s not vacc...\n",
       "5      50   60       Jane’s older brother had the flu last month.\n",
       "6      60   70           Jane had a severe case of flu last year.\n",
       "7      70   81  Joe expressed concerns about the risks of bird...\n",
       "8      81   92  Joe shows no signs of stroke, except for numbn...\n",
       "9      92  100      Nausea, vomiting and ankle swelling negative.\n",
       "10    100  105                      Patient denies alcohol abuse.\n",
       "11    105  114             Allergies: Penicillin, Dust, Sneezing.\n",
       "12    114  140  There's an outbreak of happiness in San Jose o..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt =u\"\"\"Prescribing sick days due to diagnosis of influenza.Jane complains about flu-like symptoms.Jane may be experiencing some sort of flu episode.Jane’s RIDT came back negative for influenza.\n",
    "Jane is at high risk for flu if she’s not vaccinated.Jane’s older brother had the flu last month.Jane had a severe case of flu last year.Joe expressed concerns about the risks of bird flu.\n",
    "Joe shows no signs of stroke, except for numbness.Nausea, vomiting and ankle swelling negative.Patient denies alcohol abuse. Allergies: Penicillin, Dust, Sneezing.\n",
    "There's an outbreak of happiness in San Jose organized by O'Reilly Media, today, March 15, 2017, involving thousands of people.\"\"\"\n",
    "\n",
    "print 'Language:',nlp.lang\n",
    "print 'Vocabulary size:',nlp.vocab.length\n",
    "print\n",
    "doc = nlp(txt) \n",
    "data=[]\n",
    "for sent in doc.sents:\n",
    "#     print 'Text:',sent.text.replace('\\n','')\n",
    "#     print 'Start:',sent.start,'End:',sent.end\n",
    "    data.append((sent.start,sent.end,sent.text.replace('\\n','')))\n",
    "import pandas as pd\n",
    "sents = pd.DataFrame(data=data,columns = ['Start','End','Sentence Text'])\n",
    "sents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Part of speech tagging and Named Entity extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Token</th>\n",
       "      <th>Id_in_vocab</th>\n",
       "      <th>Lemma</th>\n",
       "      <th>POS</th>\n",
       "      <th>Depends_on</th>\n",
       "      <th>Dependency_type</th>\n",
       "      <th>Entity_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Prescribing</td>\n",
       "      <td>258460</td>\n",
       "      <td>prescribe</td>\n",
       "      <td>VERB</td>\n",
       "      <td>days</td>\n",
       "      <td>amod</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>sick</td>\n",
       "      <td>1239</td>\n",
       "      <td>sick</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>days</td>\n",
       "      <td>amod</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17</td>\n",
       "      <td>days</td>\n",
       "      <td>360</td>\n",
       "      <td>day</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>days</td>\n",
       "      <td>ROOT</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22</td>\n",
       "      <td>due</td>\n",
       "      <td>586</td>\n",
       "      <td>due</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>days</td>\n",
       "      <td>amod</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26</td>\n",
       "      <td>to</td>\n",
       "      <td>5</td>\n",
       "      <td>to</td>\n",
       "      <td>ADP</td>\n",
       "      <td>due</td>\n",
       "      <td>pcomp</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>29</td>\n",
       "      <td>diagnosis</td>\n",
       "      <td>8171</td>\n",
       "      <td>diagnosis</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>due</td>\n",
       "      <td>pobj</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>39</td>\n",
       "      <td>of</td>\n",
       "      <td>8</td>\n",
       "      <td>of</td>\n",
       "      <td>ADP</td>\n",
       "      <td>diagnosis</td>\n",
       "      <td>prep</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>42</td>\n",
       "      <td>influenza</td>\n",
       "      <td>47577</td>\n",
       "      <td>influenza</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>of</td>\n",
       "      <td>pobj</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>51</td>\n",
       "      <td>.</td>\n",
       "      <td>1</td>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>days</td>\n",
       "      <td>punct</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>52</td>\n",
       "      <td>Jane</td>\n",
       "      <td>10305</td>\n",
       "      <td>jane</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>complains</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>57</td>\n",
       "      <td>complains</td>\n",
       "      <td>10306</td>\n",
       "      <td>complain</td>\n",
       "      <td>VERB</td>\n",
       "      <td>complains</td>\n",
       "      <td>ROOT</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>67</td>\n",
       "      <td>about</td>\n",
       "      <td>50</td>\n",
       "      <td>about</td>\n",
       "      <td>ADP</td>\n",
       "      <td>complains</td>\n",
       "      <td>prep</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>73</td>\n",
       "      <td>flu</td>\n",
       "      <td>8740</td>\n",
       "      <td>flu</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>like</td>\n",
       "      <td>npadvmod</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>76</td>\n",
       "      <td>-</td>\n",
       "      <td>35</td>\n",
       "      <td>-</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>like</td>\n",
       "      <td>punct</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>77</td>\n",
       "      <td>like</td>\n",
       "      <td>39</td>\n",
       "      <td>like</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>symptoms</td>\n",
       "      <td>amod</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>82</td>\n",
       "      <td>symptoms</td>\n",
       "      <td>4223</td>\n",
       "      <td>symptom</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>about</td>\n",
       "      <td>pobj</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>90</td>\n",
       "      <td>.</td>\n",
       "      <td>1</td>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>complains</td>\n",
       "      <td>punct</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>91</td>\n",
       "      <td>Jane</td>\n",
       "      <td>10305</td>\n",
       "      <td>jane</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>experiencing</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>96</td>\n",
       "      <td>may</td>\n",
       "      <td>238</td>\n",
       "      <td>may</td>\n",
       "      <td>VERB</td>\n",
       "      <td>experiencing</td>\n",
       "      <td>aux</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>100</td>\n",
       "      <td>be</td>\n",
       "      <td>25</td>\n",
       "      <td>be</td>\n",
       "      <td>VERB</td>\n",
       "      <td>experiencing</td>\n",
       "      <td>aux</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>103</td>\n",
       "      <td>experiencing</td>\n",
       "      <td>5558</td>\n",
       "      <td>experience</td>\n",
       "      <td>VERB</td>\n",
       "      <td>experiencing</td>\n",
       "      <td>ROOT</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>116</td>\n",
       "      <td>some</td>\n",
       "      <td>78</td>\n",
       "      <td>some</td>\n",
       "      <td>DET</td>\n",
       "      <td>sort</td>\n",
       "      <td>det</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>121</td>\n",
       "      <td>sort</td>\n",
       "      <td>511</td>\n",
       "      <td>sort</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>experiencing</td>\n",
       "      <td>dobj</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>126</td>\n",
       "      <td>of</td>\n",
       "      <td>8</td>\n",
       "      <td>of</td>\n",
       "      <td>ADP</td>\n",
       "      <td>sort</td>\n",
       "      <td>prep</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>129</td>\n",
       "      <td>flu</td>\n",
       "      <td>8740</td>\n",
       "      <td>flu</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>episode</td>\n",
       "      <td>compound</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>133</td>\n",
       "      <td>episode</td>\n",
       "      <td>1056</td>\n",
       "      <td>episode</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>of</td>\n",
       "      <td>pobj</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>140</td>\n",
       "      <td>.</td>\n",
       "      <td>1</td>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>experiencing</td>\n",
       "      <td>punct</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>141</td>\n",
       "      <td>Jane</td>\n",
       "      <td>10305</td>\n",
       "      <td>jane</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>RIDT</td>\n",
       "      <td>compound</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>145</td>\n",
       "      <td>’s</td>\n",
       "      <td>283876</td>\n",
       "      <td>’s</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>RIDT</td>\n",
       "      <td>compound</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>148</td>\n",
       "      <td>RIDT</td>\n",
       "      <td>0</td>\n",
       "      <td>ridt</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>came</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>528</td>\n",
       "      <td>,</td>\n",
       "      <td>2</td>\n",
       "      <td>,</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>Dust</td>\n",
       "      <td>punct</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>530</td>\n",
       "      <td>Sneezing</td>\n",
       "      <td>96213</td>\n",
       "      <td>sneezing</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>Penicillin</td>\n",
       "      <td>conj</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>538</td>\n",
       "      <td>.</td>\n",
       "      <td>1</td>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>Allergies</td>\n",
       "      <td>punct</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>539</td>\n",
       "      <td>\\n</td>\n",
       "      <td>64</td>\n",
       "      <td>\\n</td>\n",
       "      <td>SPACE</td>\n",
       "      <td>.</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>540</td>\n",
       "      <td>There</td>\n",
       "      <td>178</td>\n",
       "      <td>there</td>\n",
       "      <td>ADV</td>\n",
       "      <td>'s</td>\n",
       "      <td>expl</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>545</td>\n",
       "      <td>'s</td>\n",
       "      <td>15</td>\n",
       "      <td>'</td>\n",
       "      <td>VERB</td>\n",
       "      <td>'s</td>\n",
       "      <td>ROOT</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>548</td>\n",
       "      <td>an</td>\n",
       "      <td>60</td>\n",
       "      <td>an</td>\n",
       "      <td>DET</td>\n",
       "      <td>outbreak</td>\n",
       "      <td>det</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>551</td>\n",
       "      <td>outbreak</td>\n",
       "      <td>16307</td>\n",
       "      <td>outbreak</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>'s</td>\n",
       "      <td>attr</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>560</td>\n",
       "      <td>of</td>\n",
       "      <td>8</td>\n",
       "      <td>of</td>\n",
       "      <td>ADP</td>\n",
       "      <td>outbreak</td>\n",
       "      <td>prep</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>563</td>\n",
       "      <td>happiness</td>\n",
       "      <td>3500</td>\n",
       "      <td>happiness</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>of</td>\n",
       "      <td>pobj</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>573</td>\n",
       "      <td>in</td>\n",
       "      <td>14</td>\n",
       "      <td>in</td>\n",
       "      <td>ADP</td>\n",
       "      <td>outbreak</td>\n",
       "      <td>prep</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>576</td>\n",
       "      <td>San</td>\n",
       "      <td>3053</td>\n",
       "      <td>san</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>Jose</td>\n",
       "      <td>compound</td>\n",
       "      <td>GPE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>580</td>\n",
       "      <td>Jose</td>\n",
       "      <td>11244</td>\n",
       "      <td>jose</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>in</td>\n",
       "      <td>pobj</td>\n",
       "      <td>GPE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>585</td>\n",
       "      <td>organized</td>\n",
       "      <td>4730</td>\n",
       "      <td>organize</td>\n",
       "      <td>VERB</td>\n",
       "      <td>outbreak</td>\n",
       "      <td>acl</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>595</td>\n",
       "      <td>by</td>\n",
       "      <td>83</td>\n",
       "      <td>by</td>\n",
       "      <td>ADP</td>\n",
       "      <td>organized</td>\n",
       "      <td>agent</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>598</td>\n",
       "      <td>O'Reilly</td>\n",
       "      <td>19344</td>\n",
       "      <td>o'reilly</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>Media</td>\n",
       "      <td>compound</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>607</td>\n",
       "      <td>Media</td>\n",
       "      <td>9337</td>\n",
       "      <td>media</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>by</td>\n",
       "      <td>pobj</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>612</td>\n",
       "      <td>,</td>\n",
       "      <td>2</td>\n",
       "      <td>,</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>outbreak</td>\n",
       "      <td>punct</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>614</td>\n",
       "      <td>today</td>\n",
       "      <td>520</td>\n",
       "      <td>today</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>outbreak</td>\n",
       "      <td>npadvmod</td>\n",
       "      <td>DATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>619</td>\n",
       "      <td>,</td>\n",
       "      <td>2</td>\n",
       "      <td>,</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>outbreak</td>\n",
       "      <td>punct</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>621</td>\n",
       "      <td>March</td>\n",
       "      <td>4611</td>\n",
       "      <td>march</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>'s</td>\n",
       "      <td>npadvmod</td>\n",
       "      <td>DATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>627</td>\n",
       "      <td>15</td>\n",
       "      <td>786</td>\n",
       "      <td>15</td>\n",
       "      <td>NUM</td>\n",
       "      <td>March</td>\n",
       "      <td>nummod</td>\n",
       "      <td>DATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>629</td>\n",
       "      <td>,</td>\n",
       "      <td>2</td>\n",
       "      <td>,</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>March</td>\n",
       "      <td>punct</td>\n",
       "      <td>DATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>631</td>\n",
       "      <td>2017</td>\n",
       "      <td>21930</td>\n",
       "      <td>2017</td>\n",
       "      <td>NUM</td>\n",
       "      <td>March</td>\n",
       "      <td>appos</td>\n",
       "      <td>DATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>635</td>\n",
       "      <td>,</td>\n",
       "      <td>2</td>\n",
       "      <td>,</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>March</td>\n",
       "      <td>punct</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>637</td>\n",
       "      <td>involving</td>\n",
       "      <td>5002</td>\n",
       "      <td>involve</td>\n",
       "      <td>VERB</td>\n",
       "      <td>March</td>\n",
       "      <td>acl</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>647</td>\n",
       "      <td>thousands</td>\n",
       "      <td>1874</td>\n",
       "      <td>thousand</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>involving</td>\n",
       "      <td>dobj</td>\n",
       "      <td>CARDINAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>657</td>\n",
       "      <td>of</td>\n",
       "      <td>8</td>\n",
       "      <td>of</td>\n",
       "      <td>ADP</td>\n",
       "      <td>thousands</td>\n",
       "      <td>prep</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>660</td>\n",
       "      <td>people</td>\n",
       "      <td>65</td>\n",
       "      <td>people</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>of</td>\n",
       "      <td>pobj</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>666</td>\n",
       "      <td>.</td>\n",
       "      <td>1</td>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>'s</td>\n",
       "      <td>punct</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>140 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Index         Token  Id_in_vocab       Lemma    POS    Depends_on  \\\n",
       "0        0   Prescribing       258460   prescribe   VERB          days   \n",
       "1       12          sick         1239        sick    ADJ          days   \n",
       "2       17          days          360         day   NOUN          days   \n",
       "3       22           due          586         due    ADJ          days   \n",
       "4       26            to            5          to    ADP           due   \n",
       "5       29     diagnosis         8171   diagnosis   NOUN           due   \n",
       "6       39            of            8          of    ADP     diagnosis   \n",
       "7       42     influenza        47577   influenza   NOUN            of   \n",
       "8       51             .            1           .  PUNCT          days   \n",
       "9       52          Jane        10305        jane  PROPN     complains   \n",
       "10      57     complains        10306    complain   VERB     complains   \n",
       "11      67         about           50       about    ADP     complains   \n",
       "12      73           flu         8740         flu   NOUN          like   \n",
       "13      76             -           35           -  PUNCT          like   \n",
       "14      77          like           39        like    ADJ      symptoms   \n",
       "15      82      symptoms         4223     symptom   NOUN         about   \n",
       "16      90             .            1           .  PUNCT     complains   \n",
       "17      91          Jane        10305        jane  PROPN  experiencing   \n",
       "18      96           may          238         may   VERB  experiencing   \n",
       "19     100            be           25          be   VERB  experiencing   \n",
       "20     103  experiencing         5558  experience   VERB  experiencing   \n",
       "21     116          some           78        some    DET          sort   \n",
       "22     121          sort          511        sort   NOUN  experiencing   \n",
       "23     126            of            8          of    ADP          sort   \n",
       "24     129           flu         8740         flu   NOUN       episode   \n",
       "25     133       episode         1056     episode   NOUN            of   \n",
       "26     140             .            1           .  PUNCT  experiencing   \n",
       "27     141          Jane        10305        jane  PROPN          RIDT   \n",
       "28     145            ’s       283876          ’s  PROPN          RIDT   \n",
       "29     148          RIDT            0        ridt  PROPN          came   \n",
       "..     ...           ...          ...         ...    ...           ...   \n",
       "110    528             ,            2           ,  PUNCT          Dust   \n",
       "111    530      Sneezing        96213    sneezing  PROPN    Penicillin   \n",
       "112    538             .            1           .  PUNCT     Allergies   \n",
       "113    539            \\n           64          \\n  SPACE             .   \n",
       "114    540         There          178       there    ADV            's   \n",
       "115    545            's           15           '   VERB            's   \n",
       "116    548            an           60          an    DET      outbreak   \n",
       "117    551      outbreak        16307    outbreak   NOUN            's   \n",
       "118    560            of            8          of    ADP      outbreak   \n",
       "119    563     happiness         3500   happiness   NOUN            of   \n",
       "120    573            in           14          in    ADP      outbreak   \n",
       "121    576           San         3053         san  PROPN          Jose   \n",
       "122    580          Jose        11244        jose  PROPN            in   \n",
       "123    585     organized         4730    organize   VERB      outbreak   \n",
       "124    595            by           83          by    ADP     organized   \n",
       "125    598      O'Reilly        19344    o'reilly  PROPN         Media   \n",
       "126    607         Media         9337       media  PROPN            by   \n",
       "127    612             ,            2           ,  PUNCT      outbreak   \n",
       "128    614         today          520       today   NOUN      outbreak   \n",
       "129    619             ,            2           ,  PUNCT      outbreak   \n",
       "130    621         March         4611       march  PROPN            's   \n",
       "131    627            15          786          15    NUM         March   \n",
       "132    629             ,            2           ,  PUNCT         March   \n",
       "133    631          2017        21930        2017    NUM         March   \n",
       "134    635             ,            2           ,  PUNCT         March   \n",
       "135    637     involving         5002     involve   VERB         March   \n",
       "136    647     thousands         1874    thousand   NOUN     involving   \n",
       "137    657            of            8          of    ADP     thousands   \n",
       "138    660        people           65      people   NOUN            of   \n",
       "139    666             .            1           .  PUNCT            's   \n",
       "\n",
       "    Dependency_type Entity_Type  \n",
       "0              amod              \n",
       "1              amod              \n",
       "2              ROOT              \n",
       "3              amod              \n",
       "4             pcomp              \n",
       "5              pobj              \n",
       "6              prep              \n",
       "7              pobj              \n",
       "8             punct              \n",
       "9             nsubj      PERSON  \n",
       "10             ROOT              \n",
       "11             prep              \n",
       "12         npadvmod              \n",
       "13            punct              \n",
       "14             amod              \n",
       "15             pobj              \n",
       "16            punct              \n",
       "17            nsubj      PERSON  \n",
       "18              aux              \n",
       "19              aux              \n",
       "20             ROOT              \n",
       "21              det              \n",
       "22             dobj              \n",
       "23             prep              \n",
       "24         compound              \n",
       "25             pobj              \n",
       "26            punct              \n",
       "27         compound      PERSON  \n",
       "28         compound      PERSON  \n",
       "29            nsubj      PERSON  \n",
       "..              ...         ...  \n",
       "110           punct              \n",
       "111            conj              \n",
       "112           punct              \n",
       "113                              \n",
       "114            expl              \n",
       "115            ROOT              \n",
       "116             det              \n",
       "117            attr              \n",
       "118            prep              \n",
       "119            pobj              \n",
       "120            prep              \n",
       "121        compound         GPE  \n",
       "122            pobj         GPE  \n",
       "123             acl              \n",
       "124           agent              \n",
       "125        compound         ORG  \n",
       "126            pobj         ORG  \n",
       "127           punct              \n",
       "128        npadvmod        DATE  \n",
       "129           punct              \n",
       "130        npadvmod        DATE  \n",
       "131          nummod        DATE  \n",
       "132           punct        DATE  \n",
       "133           appos        DATE  \n",
       "134           punct              \n",
       "135             acl              \n",
       "136            dobj    CARDINAL  \n",
       "137            prep              \n",
       "138            pobj              \n",
       "139           punct              \n",
       "\n",
       "[140 rows x 8 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = []\n",
    "for sent in doc.sents:\n",
    "    for w in sent:\n",
    "        tmp=[]\n",
    "        tmp.append(w.idx)\n",
    "        tmp.append(w.text)\n",
    "        tmp.append(w.lex_id)\n",
    "        tmp.append(w.lemma_)\n",
    "        tmp.append(w.pos_)\n",
    "        tmp.append(w.head)\n",
    "        tmp.append(w.dep_)\n",
    "        tmp.append(w.ent_type_)\n",
    "#         tmp.append(w.sentiment)\n",
    "#         tmp.append(sent.text)\n",
    "#         tmp.append(sent.label_)\n",
    "        data.append(tmp)\n",
    "tokens = pd.DataFrame(data=data, columns = ['Index','Token','Id_in_vocab',\n",
    "        'Lemma','POS','Depends_on','Dependency_type','Entity_Type'])\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Using the syntactic dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject:  Jane  verb:  complains\n",
      "Subject:  Jane  verb:  experiencing\n",
      "Subject:  RIDT  verb:  came\n",
      "Subject:  Jane  verb:  is\n",
      "Subject:  Jane  verb:  had\n",
      "Subject:  brother  verb:  had\n",
      "Subject:  Jane  verb:  had\n",
      "Subject:  Joe  verb:  expressed\n",
      "Subject:  Joe  verb:  shows\n",
      "Subject:  ankle  verb:  swelling\n",
      "Subject:  Patient  verb:  denies\n"
     ]
    }
   ],
   "source": [
    "from spacy.symbols import nsubj, VERB\n",
    "# Finding a verb with a subject \n",
    "pairs = []\n",
    "for possible_subject in doc:\n",
    "    if possible_subject.dep == nsubj and possible_subject.head.pos == VERB:\n",
    "        pairs.append((possible_subject,possible_subject.head))\n",
    "\n",
    "for pair in pairs:\n",
    "    print 'Subject: ',pair[0],' verb: ',pair[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Costum pipeline... Adding negation detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from negex import *\n",
    "rfile = open(r'negex_triggers.txt')\n",
    "irules = sortRules(rfile.readlines())\n",
    "\n",
    "def negation_tag(doc):\n",
    "    for sent in doc.sents:\n",
    "        ph= set()\n",
    "        for word in sent:\n",
    "            if word.pos_!='ADP' and word.pos_!='PUNCT':\n",
    "                ph.add(word.text)\n",
    "        tagger = negTagger(sentence = sent.text, phrases = list(ph),rules = irules, negP=False)\n",
    "        scopes=  tagger.getScopes()\n",
    "        res = set()\n",
    "        for scope in scopes:\n",
    "            s = scope.replace('[NEGATED]','').replace('.','').replace(',','')\n",
    "            if ' ' in s:\n",
    "                for wd in s.split(' '):\n",
    "                    res.add(wd)\n",
    "            else:\n",
    "                res.add(s)\n",
    "        for word in sent:\n",
    "            if word.text in res:\n",
    "                word.dep_ = u'NEGATED'\n",
    "            else:\n",
    "                word.dep_= u'AFFIRMATIVE'\n",
    "\n",
    "\n",
    "def custom_pipeline(nlp):\n",
    "    return (nlp.tagger,nlp.parser,negation_tag)\n",
    "\n",
    "nlp_neg = spacy.load('en', create_pipeline=custom_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jane is at high risk for flu if she’s not vaccinated.\n",
      "Negated words:  [vaccinated]\n",
      "Joe shows no signs of stroke, except for numbness.\n",
      "Negated words:  [stroke]\n",
      "Patient denies alcohol abuse.\n",
      "Negated words:  [alcohol, abuse]\n"
     ]
    }
   ],
   "source": [
    "doc2 = nlp_neg(txt)\n",
    "for sent in doc2.sents:\n",
    "    negs = []\n",
    "    for word in sent:\n",
    "        if word.dep_==u'NEGATED':\n",
    "            negs.append(word)\n",
    "#         if word.dep_== u'NEGATED':\n",
    "#             negs.append[word]\n",
    "    if len(negs)>0:\n",
    "        print sent\n",
    "        print 'Negated words: ',negs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
